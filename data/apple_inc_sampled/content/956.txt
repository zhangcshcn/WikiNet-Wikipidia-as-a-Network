

  In
  
   computer architecture
  
  ,
  
   64-bit computing
  
  is the use of
  
   processors
  
  that have
  
   datapath
  
  widths,
  
   integer
  
  size, and
  
   memory address
  
  widths of 64
  
   bits
  
  (eight
  
   octets
  
  ). Also, 64-bit
  
   computer architectures
  
  for
  
   central processing units
  
  (CPUs) and
  
   arithmetic logic units
  
  (ALUs) are those that are based on
  
   processor registers
  
  ,
  
   address buses
  
  , or
  
   data buses
  
  of that size. From the software perspective, 64-bit computing means the use of
  
   code
  
  with 64-bit
  
   virtual memory
  
  addresses. However, not all 64-bit instruction sets support full 64-bit virtual memory addresses;
  
   x86-64
  
  and
  
   ARMv8
  
  , for example, support only 48 bits of virtual address, with the remaining 16 bits of the virtual address required to be all 0's or all 1's, and several 64-bit instruction sets support fewer than 64 bits of physical memory address.
 
  The term
  
   64-bit
  
  describes a generation of computers in which 64-bit processors are the norm. 64 bits is a
  
   word
  
  size that defines certain classes of computer architecture, buses, memory and CPUs, and by extension the software that runs on them. 64-bit CPUs have been used in
  
   supercomputers
  
  since the 1970s (
  
   Cray-1
  
  , 1975) and in
  
   reduced instruction set computing
  
  (RISC) based
  
   workstations
  
  and
  
   servers
  
  since the early 1990s, notably the
  
   MIPS
  

   R4000
  
  ,
  
   R8000
  
  , and
  
   R10000
  
  , the
  
   DEC
  

   Alpha
  
  , the
  
   Sun
  

   UltraSPARC
  
  , and the
  
   IBM
  

   RS64
  
  and
  
   POWER3
  
  and later
  
   POWER
  

   microprocessors
  
  . In 2003, 64-bit CPUs were introduced to the (formerly
  
   32-bit
  
  ) mainstream
  
   personal computer
  
  market in the form of
  
   x86-64
  
  processors and the
  
   PowerPC G5
  
  ; and in 2012
  

    [1]
   

  even into the
  
   ARM architecture
  
  targeting
  
   smartphones
  
  and
  
   tablet computers
  
  , first sold on September 20, 2013, in the
  
   iPhone 5S
  
  powered by the
  
   ARMv8-A
  

   Apple A7
  

   system on a chip
  
  (SoC).
 
  A 64-bit register can store 2
  
   64
  
  (over 18
  
   quintillion
  
  or 1.8×10
  
   19
  
  ) different values. The range of
  
   integer
  
  values that can be stored in 64 bits depends on the
  
   integer representation
  
  used. With the two most common representations, the range is 0 through 18,446,744,073,709,551,615 (2
  
   64
  
  - 1) for representation as an (
  
   unsigned
  
  )
  
   binary number
  
  , and -9,223,372,036,854,775,808 (-2
  
   63
  
  ) through 9,223,372,036,854,775,807 (2
  
   63
  
  - 1) for representation as
  
   two's complement
  
  . Hence, a processor with 64-bit memory addresses can directly access 2
  
   64
  
  bytes (=16
  
   exbibytes
  
  ) of
  
   byte-addressable
  
  memory.
 
  With no further qualification, a
  
   64-bit computer architecture
  
  generally has integer and addressing
  
   processor registers
  
  that are 64 bits wide, allowing direct support for 64-bit data types and addresses. However, a CPU might have external
  
   data buses
  
  or
  
   address buses
  
  with different sizes from the registers, even larger (the 32-bit
  
   Pentium
  
  had a 64-bit data bus, for instance
  

    [2]
   

  ). The term may also refer to the size of low-level data types, such as 64-bit
  
   floating-point
  
  numbers.
 


  Processor registers are typically divided into several groups:
  
   integer
  
  ,
  
   floating-point
  
  ,
  
   single instruction, multiple data
  
  (
  
   SIMD
  
  ),
  
   control
  
  , and often special registers for address arithmetic which may have various uses and names such as
  
   address
  
  ,
  
   index
  
  , or
  
   base registers
  
  . However, in modern designs, these functions are often performed by more general purpose
  
   integer
  
  registers. In most processors, only integer or address-registers can be used to address data in memory; the other types of registers cannot. The size of these registers therefore normally limits the amount of directly addressable memory, even if there are registers, such as floating-point registers, that are wider.
 
  Most high performance 32-bit and 64-bit processors (some notable exceptions are older or embedded
  
   ARM architecture
  
  (ARM) and 32-bit
  
   MIPS instruction set
  
  (MIPS) CPUs) have integrated floating point hardware, which is often, but not always, based on 64-bit units of data. For example, although the
  
   x86
  
  /
  
   x87
  
  architecture has instructions able to load and store 64-bit (and 32-bit) floating-point values in memory, the internal floating point data and register format is 80 bits wide, while the general-purpose registers are 32 bits wide. In contrast, the 64-bit
  
   Alpha
  
  family uses a 64-bit floating-point data and register format, and 64-bit integer registers.
 
  Many computer
  
   instruction sets
  
  are designed so that a single integer register can store the
  
   memory address
  
  to any location in the computer's physical or
  
   virtual memory
  
  . Therefore, the total number of addresses to memory is often determined by the width of these registers. The
  
   IBM
  

   System/360
  
  of the 1960s was an early 32-bit computer; it had 32-bit integer registers, although it only used the low order 24 bits of a word for addresses, resulting in a 16
  
   MiB
  
  [
  
   16 × 1024
   
    2
   
   bytes
  
  ] address space. 32-bit
  
   superminicomputers
  
  , such as the
  
   DEC
  

   VAX
  
  , became common in the 1970s, and 32-bit microprocessors, such as the
  
   Motorola 68000 family
  
  and the
  
   32-bit members of the x86 family
  
  starting with the
  
   Intel 80386
  
  , appeared in the mid-1980s, making 32 bits something of a
  
   de facto
  
  consensus as a convenient register size.
 
  A 32-bit
  
   address register
  
  meant that 2
  
   32
  
  addresses, or 4
  
   GiB
  
  of
  
   random-access memory
  
  (RAM), could be referenced. When these architectures were devised, 4 GB of memory was so far beyond the typical amounts (4 MB) in installations, that this was considered to be enough
  
   headroom
  
  for addressing. 4.29 billion addresses were considered an appropriate size to work with for another important reason: 4.29 billion integers are enough to assign unique references to most entities in applications like
  
   databases
  
  .
 
  Some
  
   supercomputer
  
  architectures of the 1970s and 1980s, such as the
  
   Cray-1
  
  ,
  

    [3]
   

  used registers up to 64 bits wide, and supported 64-bit integer arithmetic, although they did not support 64-bit addressing. In the mid-1980s,
  
   Intel i860
  


    [4]
   

  development began culminating in a (too late
  

    [5]
   

  for Windows NT) 1989 release; the i860 had 32-bit integer registers and 32-bit addressing, so it was not a fully 64-bit processor, although its graphics unit supported 64-bit integer arithmetic.
  

    [6]
   

  However, 32 bits remained the norm until the early 1990s, when the continual reductions in the cost of memory led to installations with amounts of RAM approaching 4 GB, and the use of virtual memory spaces exceeding the 4 GB ceiling became desirable for handling certain types of problems. In response, MIPS and DEC developed 64-bit microprocessor architectures, initially for high-end
  
   workstation
  
  and
  
   server
  
  machines. By the mid-1990s,
  
   HAL Computer Systems
  
  ,
  
   Sun Microsystems
  
  ,
  
   IBM
  
  ,
  
   Silicon Graphics
  
  , and
  
   Hewlett Packard
  
  had developed 64-bit architectures for their workstation and server systems. A notable exception to this trend were
  
   mainframes
  
  from IBM, which then used 32-bit data and 31-bit address sizes; the IBM mainframes did not include 64-bit processors until 2000. During the 1990s, several low-cost 64-bit microprocessors were used in consumer electronics and embedded applications. Notably, the
  
   Nintendo 64
  


    [7]
   

  and the
  
   PlayStation 2
  
  had 64-bit microprocessors before their introduction in personal computers. High-end printers, network equipment, and industrial computers, also used 64-bit microprocessors, such as the
  
   Quantum Effect Devices
  

   R5000
  
  . 64-bit computing started to drift down to the personal computer desktop from 2003 onward, when some models in
  
   Apple
  
  's Macintosh lines switched to
  
   PowerPC 970
  
  processors (termed
  
   G5
  
  by Apple), and
  
   AMD
  
  released its first 64-bit
  
   x86-64
  
  processor.
 
  In principle, a 64-bit microprocessor can address 16
  
   EiBs
  
  (
  
   16 × 1024
   
    6
   
   = 2
   
    64
   
   = 18,446,744,073,709,551,616 bytes
  
  , or about 18.4 exabytes) of memory. However, not all instruction sets, and not all processors implementing those instruction sets, support a full 64-bit virtual or physical address space.
 
  The
  
   x86-64 architecture
  
  (as of 2016
  

    [update]
   

  ) allows 48 bits for virtual memory and, for any given processor, up to 52 bits for physical memory.
  

    [8]
   



    [9]
   

  These limits allow memory sizes of 4
  
   PiB
  
  (
  
   4 × 1024
   
    5
   
   bytes
  
  ) and 256
  
   TiB
  
  (
  
   256 × 1024
   
    4
   
   bytes
  
  ), respectively. A PC cannot currently contain 4 pebibytes of memory (due to the physical size of the memory chips), but AMD envisioned large servers, shared memory clusters, and other uses of physical address space that might approach this in the foreseeable future. Thus the 52-bit physical address provides ample room for expansion while not incurring the cost of implementing full 64-bit physical addresses. Similarly, the 48-bit virtual address space was designed to provide more than 65,000 (2
  
   16
  
  ) times the 32-bit limit of 4 GiB (
  
   4 × 1024
   
    3
   
   bytes
  
  ), allowing room for later expansion and incurring no overhead of translating full 64-bit addresses.
 
  The
  
   Power ISA v3.0
  
  allows 64 bits for an effective address, mapped to a segmented address with between 65 and 78 bits allowed, for virtual memory, and, for any given processor, up to 60 bits for physical memory.
  

    [10]
   


  The Oracle
  
   SPARC
  
  Architecture 2015 allows 64 bits for virtual memory and, for any given processor, between 40 and 56 bits for physical memory.
  

    [11]
   


  The
  
   ARM AArch64 Virtual Memory System Architecture
  
  allows 48 bits for virtual memory and, for any given processor, from 32 to 48 bits for physical memory.
  

    [12]
   


  A change from a
  
   32-bit
  
  to a 64-bit architecture is a fundamental alteration, as most
  
   operating systems
  
  must be extensively modified to take advantage of the new architecture, because that software has to manage the actual memory addressing hardware.
  

    [29]
   

  Other software must also be
  
   ported
  
  to use the new abilities; older 32-bit software may be supported either by virtue of the 64-bit instruction set being a superset of the 32-bit instruction set, so that processors that support the 64-bit instruction set can also run code for the 32-bit instruction set, or through software
  
   emulation
  
  , or by the actual implementation of a 32-bit processor core within the 64-bit processor, as with some Itanium processors from Intel, which included an
  
   IA-32
  
  processor core to run 32-bit
  
   x86
  
  applications. The operating systems for those 64-bit architectures generally support both 32-bit and 64-bit applications.
  

    [30]
   


  One significant exception to this is the
  
   AS/400
  
  , which software runs on a virtual
  
   instruction set architecture
  
  (ISA) called
  
   Technology Independent Machine Interface
  
  (TIMI), which is translated to native machine code by low-level software before being executed. The translation software is all that must be rewritten to move the full OS and all software to a new platform, as when IBM transitioned the native instruction set for AS/400 from the older 32/48-bit
  
   IMPI
  
  to the newer 64-bit
  
   PowerPC-AS
  
  , codenamed
  
   Amazon
  
  . The instruction set for IMPI was quite different than for 32-bit PowerPC, so this transition was even bigger than moving a given instruction set from 32 to 64 bits.
 
  On 64-bit hardware with
  
   x86-64
  
  architecture (AMD64), most 32-bit operating systems and applications can run with no compatibility issues. While the larger address space of 64-bit architectures makes working with large data sets in applications such as
  
   digital video
  
  , scientific computing, and large
  
   databases
  
  easier, there has been considerable debate on whether they or their 32-bit compatibility modes will be faster than comparably priced 32-bit systems for other tasks.
 
  A compiled Java program can run on a 32- or 64-bit Java virtual machine with no modification. The lengths and precision of all the built-in types, such as
  
   char
  
  ,
  
   short
  
  ,
  
   int
  
  ,
  
   long
  
  ,
  
   float
  
  , and
  
   double
  
  , and the types that can be used as array indices, are specified by the standard and are not dependent on the underlying architecture. Java programs that run on a 64-bit Java virtual machine have access to a larger address space.
  

    [31]
   


  Speed is not the only factor to consider in comparing 32-bit and 64-bit processors. Applications such as multi-tasking, stress testing, and clustering – for
  
   high-performance computing
  
  (HPC) – may be more suited to a 64-bit architecture when deployed appropriately. For this reason, 64-bit clusters have been widely deployed in large organizations, such as IBM, HP, and Microsoft.
 

   Summary:
  

  A common misconception is that 64-bit architectures are no better than 32-bit architectures unless the computer has more than 4 GiB of
  
   random-access memory
  
  .
  

    [32]
   

  This is not entirely true:
 
  The main disadvantage of 64-bit architectures is that, relative to 32-bit architectures, the same data occupies more space in memory (due to longer pointers and possibly other types, and alignment padding). This increases the memory requirements of a given process and can have implications for efficient processor cache use. Maintaining a partial 32-bit model is one way to handle this, and is in general reasonably effective. For example, the
  
   z/OS
  
  operating system takes this approach, requiring program code to reside in 31-bit address spaces (the high order bit is not used in address calculation on the underlying hardware platform) while data objects can optionally reside in 64-bit regions.
 
  As of June 2011
  

    [update]
   

  , most proprietary
  
   x86
  
  software is compiled into 32-bit code, with less being also compiled into 64-bit code (although the trend is rapidly equalizing
  
   [
   


      citation needed
     


   ]
  
  ), so most of that software does not take advantage of the larger 64-bit address space or wider 64-bit registers and data paths on
  
   x86-64
  
  processors, or the additional general-purpose registers.
  
   [
   


      citation needed
     


   ]
  
  However, users of most RISC platforms, and users of
  
   free
  
  or
  
   open source
  
  operating systems (where the
  
   source code
  
  is available for recompiling with a 64-bit compiler) have been able to use exclusive 64-bit computing environments for years. Not all such applications require a large address space or manipulate 64-bit data items, so these applications do not benefit from these features. The main advantage of 64-bit versions of such applications is the ability to access more registers in the x86-64 architecture.
 
  x86-based 64-bit systems sometimes lack equivalents of
  
   software
  
  that is written for 32-bit architectures. The most severe problem in Microsoft Windows is incompatible
  
   device drivers
  
  for obsolete hardware. Most 32-bit application software can run on a 64-bit operating system in a compatibility mode, also termed an
  
   emulation
  
  mode, e.g., Microsoft
  
   WoW64
  
  Technology for IA-64 and AMD64. The 64-bit Windows Native Mode
  

    [35]
   

  driver environment runs atop 64-bit NTDLL.DLL, which cannot call 32-bit Win32 subsystem code (often devices whose actual hardware function is emulated in user mode software, like Winprinters). Because 64-bit drivers for most devices were unavailable until early 2007 (Vista x64), using a 64-bit version of Windows was considered a challenge. However, the trend has since moved toward 64-bit computing, more so as memory prices dropped and the use of more than 4 GB of RAM increased. Most manufacturers started to provide both 32-bit and 64-bit drivers for new devices, so unavailability of 64-bit drivers ceased to be a problem. 64-bit drivers were not provided for many older devices, which could consequently not be used in 64-bit systems.
 
  Driver compatibility was less of a problem with open-source drivers, as 32-bit ones could be modified for 64-bit use. Support for hardware made before early 2007, was problematic for open-source platforms,
  
   [
   


      citation needed
     


   ]
  
  due to the relatively small number of users.
 
  64-bit versions of Windows cannot run
  
   16-bit software
  
  . However, most 32-bit applications will work well. 64-bit users are forced to download a
  
   virtual machine
  
  of a 16- or 32-bit operating system to run old applications.
  

    [36]
   



   Mac OS X 10.4
  
  "Tiger" and
  
   Mac OS X 10.5
  
  "Leopard" only had a 32-bit kernel, but it can run 64-bit user-mode code on 64-bit-able processors.
  
   Mac OS X 10.6
  
  "Snow Leopard" had both 32- and 64-bit kernels, and, on most Macs, used the 32-bit kernel even on 64-bit processors. This allowed those Macs to support 64-bit processes while still supporting 32-bit device drivers; although not 64-bit drivers and performance advantages that can come with them.
  
   Mac OS X 10.7
  
  "Lion" ran with a 64-bit kernel on more Macs, and
  
   OS X 10.8
  
  "Mountain Lion" only has a 64-bit kernel. On systems with 64-bit processors, both the 32- and 64-bit
  
   macOS
  
  kernels can run 32-bit user-mode code, and all versions of macOS include 32-bit versions of libraries that 32-bit applications would use, so 32-bit user-mode software for macOS will run on those systems.
 

   Linux
  
  and most other
  
   Unix-like
  
  operating systems, and the
  
   C
  
  and
  
   C++
  

   toolchains
  
  for them, have supported 64-bit processors for many years. Many applications and libraries for those platforms are
  
   open source
  
  , written in C and C++, so that if they are 64-bit-safe, they can be compiled into 64-bit versions. This source-based distribution model, with an emphasis on frequent releases, makes availability of application software for those operating systems less of an issue.
 
  In 32-bit programs,
  
   pointers
  
  and data types such as integers generally have the same length. This is not necessarily true on 64-bit machines.
  

    [37]
   



    [38]
   



    [39]
   

  Mixing data types in programming languages such as
  
   C
  
  and its descendants such as
  
   C++
  
  and
  
   Objective-C
  
  may thus work on 32-bit implementations but not on 64-bit implementations.
 
  In many programming environments for C and C-derived languages on 64-bit machines,
  
   int
  
  variables are still 32 bits wide, but long integers and pointers are 64 bits wide. These are described as having an
  
   LP64
  

   data model
  
  . Another alternative is the
  
   ILP64
  
  data model in which all three data types are 64 bits wide, and even
  
   SILP64
  
  where
  
   short
  
  integers are also 64 bits wide.
  

    [40]
   

  However, in most cases the modifications required are relatively minor and straightforward, and many well-written programs can simply be recompiled for the new environment with no changes. Another alternative is the
  
   LLP64
  
  model, which maintains compatibility with 32-bit code by leaving both
  
   int
  
  and
  
   long
  
  as 32-bit.
  
   LL
  
  refers to the
  
   long long integer
  
  type, which is at least 64 bits on all platforms, including 32-bit environments.
 
  Many 64-bit platforms today use an
  
   LP64
  
  model (including Solaris,
  
   AIX
  
  ,
  
   HP-UX
  
  , Linux, macOS, BSD, and IBM z/OS). Microsoft Windows uses an
  
   LLP64
  
  model. The disadvantage of the LP64 model is that storing a
  
   long
  
  into an
  
   int
  
  may overflow. On the other hand, converting a pointer to a
  
   long
  
  will “work” in LP64. In the LLP64 model, the reverse is true. These are not problems which affect fully standard-compliant code, but code is often written with implicit assumptions about the widths of data types. C code should prefer (
  
   u
  
  )
  
   intptr_t
  
  instead of
  
   long
  
  when casting pointers into integer objects.
 
  A programming model is a choice made to suit a given compiler, and several can coexist on the same OS. However, the programming model chosen as the primary model for the OS
  
   application programming interface
  
  (API) typically dominates.
 
  Another consideration is the data model used for
  
   device drivers
  
  . Drivers make up the majority of the operating system code in most modern operating systems
  
   [
   


      citation needed
     


   ]
  
  (although many may not be loaded when the operating system is running). Many drivers use pointers heavily to manipulate data, and in some cases have to load pointers of a certain size into the hardware they support for
  
   direct memory access
  
  (DMA). As an example, a driver for a 32-bit PCI device asking the device to DMA data into upper areas of a 64-bit machine's memory could not satisfy requests from the operating system to load data from the device to memory above the 4 gibibyte barrier, because the pointers for those addresses would not fit into the DMA registers of the device. This problem is solved by having the OS take the memory restrictions of the device into account when generating requests to drivers for DMA, or by using an
  
   input–output memory management unit
  
  (IOMMU).
 
  As of January 2017
  

    [update]
   

  , 64-bit architectures for which processors are being manufactured include:
 
  Most architectures of 64 bits that are derived from the same architecture of 32 bits can execute code written for the 32-bit versions natively, with no performance penalty.
  
   [
   


      citation needed
     


   ]
  
  This kind of support is commonly called
  
   bi-arch support
  
  or more generally
  
   multi-arch support
  
  .
 